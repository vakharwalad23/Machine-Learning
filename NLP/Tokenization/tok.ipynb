{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26b0d82",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "- It is the process of converting a sequence of characters into a sequence of tokens. A token is a string of characters that represents a unit of meaning, such as a word, punctuation mark, or special character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a6546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Tokenization is the process of converting a sequence of characters into a sequence of tokens. A token is a string of characters that represents a unit of meaning, such as a word, punctuation mark, or special character.\n",
    "This process is essential in natural language processing (NLP) tasks, as it allows for the analysis and manipulation of text data.\n",
    "There are several methods of tokenization, including word tokenization, sentence tokenization, and subword tokenization. Each method has its own advantages and disadvantages, and the choice of method depends on the specific NLP task at hand.\n",
    "Tokenization is a crucial step in many NLP applications, such as text classification, sentiment analysis, and machine translation.\n",
    "It is base of any NLP task!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef194faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tokenization is the process of converting a sequence of characters into a sequence of tokens. A token is a string of characters that represents a unit of meaning, such as a word, punctuation mark, or special character.\\nThis process is essential in natural language processing (NLP) tasks, as it allows for the analysis and manipulation of text data.\\nThere are several methods of tokenization, including word tokenization, sentence tokenization, and subword tokenization. Each method has its own advantages and disadvantages, and the choice of method depends on the specific NLP task at hand.\\nTokenization is a crucial step in many NLP applications, such as text classification, sentiment analysis, and machine translation.\\nIt is base of any NLP task!\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35432503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/dhruvsmac/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/dhruvsmac/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Force download punkt tokenizer\n",
    "nltk.download('punkt', force=True)\n",
    "nltk.download('punkt_tab', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d547559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paragraph to Sentence Tokenization\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aae3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a4ded",
   "metadata": {},
   "source": [
    "> sentences in the nlp also known as documents or texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0535598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization is the process of converting a sequence of characters into a sequence of tokens.',\n",
       " 'A token is a string of characters that represents a unit of meaning, such as a word, punctuation mark, or special character.',\n",
       " 'This process is essential in natural language processing (NLP) tasks, as it allows for the analysis and manipulation of text data.',\n",
       " 'There are several methods of tokenization, including word tokenization, sentence tokenization, and subword tokenization.',\n",
       " 'Each method has its own advantages and disadvantages, and the choice of method depends on the specific NLP task at hand.',\n",
       " 'Tokenization is a crucial step in many NLP applications, such as text classification, sentiment analysis, and machine translation.',\n",
       " 'It is base of any NLP task!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17821364",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Word Tokenization\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "714d44ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc2c19e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'converting',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'tokens',\n",
       " '.',\n",
       " 'A',\n",
       " 'token',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'that',\n",
       " 'represents',\n",
       " 'a',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'meaning',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " 'punctuation',\n",
       " 'mark',\n",
       " ',',\n",
       " 'or',\n",
       " 'special',\n",
       " 'character',\n",
       " '.',\n",
       " 'This',\n",
       " 'process',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'as',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'for',\n",
       " 'the',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'manipulation',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'several',\n",
       " 'methods',\n",
       " 'of',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'including',\n",
       " 'word',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'sentence',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'and',\n",
       " 'subword',\n",
       " 'tokenization',\n",
       " '.',\n",
       " 'Each',\n",
       " 'method',\n",
       " 'has',\n",
       " 'its',\n",
       " 'own',\n",
       " 'advantages',\n",
       " 'and',\n",
       " 'disadvantages',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'choice',\n",
       " 'of',\n",
       " 'method',\n",
       " 'depends',\n",
       " 'on',\n",
       " 'the',\n",
       " 'specific',\n",
       " 'NLP',\n",
       " 'task',\n",
       " 'at',\n",
       " 'hand',\n",
       " '.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'step',\n",
       " 'in',\n",
       " 'many',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'base',\n",
       " 'of',\n",
       " 'any',\n",
       " 'NLP',\n",
       " 'task',\n",
       " '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9193517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word punctuation tokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d0775",
   "metadata": {},
   "source": [
    "> The word punctuation tokenizer splits the text into tokens based on both whitespace and punctuation characters. This means that it treats punctuation marks as separate tokens, which can be useful for certain NLP tasks where punctuation carries meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "defb5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_punct = wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5539a483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'converting',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'tokens',\n",
       " '.',\n",
       " 'A',\n",
       " 'token',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'that',\n",
       " 'represents',\n",
       " 'a',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'meaning',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " 'punctuation',\n",
       " 'mark',\n",
       " ',',\n",
       " 'or',\n",
       " 'special',\n",
       " 'character',\n",
       " '.',\n",
       " 'This',\n",
       " 'process',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'as',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'for',\n",
       " 'the',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'manipulation',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data',\n",
       " '.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'several',\n",
       " 'methods',\n",
       " 'of',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'including',\n",
       " 'word',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'sentence',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'and',\n",
       " 'subword',\n",
       " 'tokenization',\n",
       " '.',\n",
       " 'Each',\n",
       " 'method',\n",
       " 'has',\n",
       " 'its',\n",
       " 'own',\n",
       " 'advantages',\n",
       " 'and',\n",
       " 'disadvantages',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'choice',\n",
       " 'of',\n",
       " 'method',\n",
       " 'depends',\n",
       " 'on',\n",
       " 'the',\n",
       " 'specific',\n",
       " 'NLP',\n",
       " 'task',\n",
       " 'at',\n",
       " 'hand',\n",
       " '.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'step',\n",
       " 'in',\n",
       " 'many',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'translation',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'base',\n",
       " 'of',\n",
       " 'any',\n",
       " 'NLP',\n",
       " 'task',\n",
       " '!']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ccabbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the difference between word_tokenize and wordpunct_tokenize\n",
    "corpus2 = \"Hello! How's it going? This is an example: tokenization, NLP.\"\n",
    "word_tokens = word_tokenize(corpus2)\n",
    "wordpunct_tokens = wordpunct_tokenize(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50bcf2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '!',\n",
       " 'How',\n",
       " \"'s\",\n",
       " 'it',\n",
       " 'going',\n",
       " '?',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " ':',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8f8cb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '!',\n",
       " 'How',\n",
       " \"'\",\n",
       " 's',\n",
       " 'it',\n",
       " 'going',\n",
       " '?',\n",
       " 'This',\n",
       " 'is',\n",
       " 'an',\n",
       " 'example',\n",
       " ':',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6475447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_tokenize: Hello \t|\t wordpunct_tokenize: Hello\n",
      "word_tokenize: ! \t|\t wordpunct_tokenize: !\n",
      "word_tokenize: How \t|\t wordpunct_tokenize: How\n",
      "word_tokenize: 's \t|\t wordpunct_tokenize: '\n",
      "word_tokenize: it \t|\t wordpunct_tokenize: s\n",
      "word_tokenize: going \t|\t wordpunct_tokenize: it\n",
      "word_tokenize: ? \t|\t wordpunct_tokenize: going\n",
      "word_tokenize: This \t|\t wordpunct_tokenize: ?\n",
      "word_tokenize: is \t|\t wordpunct_tokenize: This\n",
      "word_tokenize: an \t|\t wordpunct_tokenize: is\n",
      "word_tokenize: example \t|\t wordpunct_tokenize: an\n",
      "word_tokenize: : \t|\t wordpunct_tokenize: example\n",
      "word_tokenize: tokenization \t|\t wordpunct_tokenize: :\n",
      "word_tokenize: , \t|\t wordpunct_tokenize: tokenization\n",
      "word_tokenize: NLP \t|\t wordpunct_tokenize: ,\n",
      "word_tokenize: . \t|\t wordpunct_tokenize: NLP\n"
     ]
    }
   ],
   "source": [
    "# Compare both tokenizers\n",
    "for wt, wpt in zip(word_tokens, wordpunct_tokens):\n",
    "    print(f\"word_tokenize: {wt} \\t|\\t wordpunct_tokenize: {wpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66fc208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treebank Word Tokenizer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "treebank_tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28fce401",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_toks = treebank_tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a48fa9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tokenization',\n",
       " 'is',\n",
       " 'the',\n",
       " 'process',\n",
       " 'of',\n",
       " 'converting',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'into',\n",
       " 'a',\n",
       " 'sequence',\n",
       " 'of',\n",
       " 'tokens.',\n",
       " 'A',\n",
       " 'token',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'of',\n",
       " 'characters',\n",
       " 'that',\n",
       " 'represents',\n",
       " 'a',\n",
       " 'unit',\n",
       " 'of',\n",
       " 'meaning',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'a',\n",
       " 'word',\n",
       " ',',\n",
       " 'punctuation',\n",
       " 'mark',\n",
       " ',',\n",
       " 'or',\n",
       " 'special',\n",
       " 'character.',\n",
       " 'This',\n",
       " 'process',\n",
       " 'is',\n",
       " 'essential',\n",
       " 'in',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'tasks',\n",
       " ',',\n",
       " 'as',\n",
       " 'it',\n",
       " 'allows',\n",
       " 'for',\n",
       " 'the',\n",
       " 'analysis',\n",
       " 'and',\n",
       " 'manipulation',\n",
       " 'of',\n",
       " 'text',\n",
       " 'data.',\n",
       " 'There',\n",
       " 'are',\n",
       " 'several',\n",
       " 'methods',\n",
       " 'of',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'including',\n",
       " 'word',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'sentence',\n",
       " 'tokenization',\n",
       " ',',\n",
       " 'and',\n",
       " 'subword',\n",
       " 'tokenization.',\n",
       " 'Each',\n",
       " 'method',\n",
       " 'has',\n",
       " 'its',\n",
       " 'own',\n",
       " 'advantages',\n",
       " 'and',\n",
       " 'disadvantages',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'choice',\n",
       " 'of',\n",
       " 'method',\n",
       " 'depends',\n",
       " 'on',\n",
       " 'the',\n",
       " 'specific',\n",
       " 'NLP',\n",
       " 'task',\n",
       " 'at',\n",
       " 'hand.',\n",
       " 'Tokenization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'step',\n",
       " 'in',\n",
       " 'many',\n",
       " 'NLP',\n",
       " 'applications',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'text',\n",
       " 'classification',\n",
       " ',',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'and',\n",
       " 'machine',\n",
       " 'translation.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'base',\n",
       " 'of',\n",
       " 'any',\n",
       " 'NLP',\n",
       " 'task',\n",
       " '!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "421ab866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treebank: Tokenization \t |\t wordpunct_tokenize: Tokenization\n",
      "Treebank: is \t |\t wordpunct_tokenize: is\n",
      "Treebank: the \t |\t wordpunct_tokenize: the\n",
      "Treebank: process \t |\t wordpunct_tokenize: process\n",
      "Treebank: of \t |\t wordpunct_tokenize: of\n",
      "Treebank: converting \t |\t wordpunct_tokenize: converting\n",
      "Treebank: a \t |\t wordpunct_tokenize: a\n",
      "Treebank: sequence \t |\t wordpunct_tokenize: sequence\n",
      "Treebank: of \t |\t wordpunct_tokenize: of\n",
      "Treebank: characters \t |\t wordpunct_tokenize: characters\n",
      "Treebank: into \t |\t wordpunct_tokenize: into\n",
      "Treebank: a \t |\t wordpunct_tokenize: a\n",
      "Treebank: sequence \t |\t wordpunct_tokenize: sequence\n",
      "Treebank: of \t |\t wordpunct_tokenize: of\n",
      "Treebank: tokens. \t |\t wordpunct_tokenize: tokens\n",
      "Treebank: A \t |\t wordpunct_tokenize: .\n",
      "Treebank: token \t |\t wordpunct_tokenize: A\n",
      "Treebank: is \t |\t wordpunct_tokenize: token\n",
      "Treebank: a \t |\t wordpunct_tokenize: is\n",
      "Treebank: string \t |\t wordpunct_tokenize: a\n",
      "Treebank: of \t |\t wordpunct_tokenize: string\n",
      "Treebank: characters \t |\t wordpunct_tokenize: of\n",
      "Treebank: that \t |\t wordpunct_tokenize: characters\n",
      "Treebank: represents \t |\t wordpunct_tokenize: that\n",
      "Treebank: a \t |\t wordpunct_tokenize: represents\n",
      "Treebank: unit \t |\t wordpunct_tokenize: a\n",
      "Treebank: of \t |\t wordpunct_tokenize: unit\n",
      "Treebank: meaning \t |\t wordpunct_tokenize: of\n",
      "Treebank: , \t |\t wordpunct_tokenize: meaning\n",
      "Treebank: such \t |\t wordpunct_tokenize: ,\n",
      "Treebank: as \t |\t wordpunct_tokenize: such\n",
      "Treebank: a \t |\t wordpunct_tokenize: as\n",
      "Treebank: word \t |\t wordpunct_tokenize: a\n",
      "Treebank: , \t |\t wordpunct_tokenize: word\n",
      "Treebank: punctuation \t |\t wordpunct_tokenize: ,\n",
      "Treebank: mark \t |\t wordpunct_tokenize: punctuation\n",
      "Treebank: , \t |\t wordpunct_tokenize: mark\n",
      "Treebank: or \t |\t wordpunct_tokenize: ,\n",
      "Treebank: special \t |\t wordpunct_tokenize: or\n",
      "Treebank: character. \t |\t wordpunct_tokenize: special\n",
      "Treebank: This \t |\t wordpunct_tokenize: character\n",
      "Treebank: process \t |\t wordpunct_tokenize: .\n",
      "Treebank: is \t |\t wordpunct_tokenize: This\n",
      "Treebank: essential \t |\t wordpunct_tokenize: process\n",
      "Treebank: in \t |\t wordpunct_tokenize: is\n",
      "Treebank: natural \t |\t wordpunct_tokenize: essential\n",
      "Treebank: language \t |\t wordpunct_tokenize: in\n",
      "Treebank: processing \t |\t wordpunct_tokenize: natural\n",
      "Treebank: ( \t |\t wordpunct_tokenize: language\n",
      "Treebank: NLP \t |\t wordpunct_tokenize: processing\n",
      "Treebank: ) \t |\t wordpunct_tokenize: (\n",
      "Treebank: tasks \t |\t wordpunct_tokenize: NLP\n",
      "Treebank: , \t |\t wordpunct_tokenize: )\n",
      "Treebank: as \t |\t wordpunct_tokenize: tasks\n",
      "Treebank: it \t |\t wordpunct_tokenize: ,\n",
      "Treebank: allows \t |\t wordpunct_tokenize: as\n",
      "Treebank: for \t |\t wordpunct_tokenize: it\n",
      "Treebank: the \t |\t wordpunct_tokenize: allows\n",
      "Treebank: analysis \t |\t wordpunct_tokenize: for\n",
      "Treebank: and \t |\t wordpunct_tokenize: the\n",
      "Treebank: manipulation \t |\t wordpunct_tokenize: analysis\n",
      "Treebank: of \t |\t wordpunct_tokenize: and\n",
      "Treebank: text \t |\t wordpunct_tokenize: manipulation\n",
      "Treebank: data. \t |\t wordpunct_tokenize: of\n",
      "Treebank: There \t |\t wordpunct_tokenize: text\n",
      "Treebank: are \t |\t wordpunct_tokenize: data\n",
      "Treebank: several \t |\t wordpunct_tokenize: .\n",
      "Treebank: methods \t |\t wordpunct_tokenize: There\n",
      "Treebank: of \t |\t wordpunct_tokenize: are\n",
      "Treebank: tokenization \t |\t wordpunct_tokenize: several\n",
      "Treebank: , \t |\t wordpunct_tokenize: methods\n",
      "Treebank: including \t |\t wordpunct_tokenize: of\n",
      "Treebank: word \t |\t wordpunct_tokenize: tokenization\n",
      "Treebank: tokenization \t |\t wordpunct_tokenize: ,\n",
      "Treebank: , \t |\t wordpunct_tokenize: including\n",
      "Treebank: sentence \t |\t wordpunct_tokenize: word\n",
      "Treebank: tokenization \t |\t wordpunct_tokenize: tokenization\n",
      "Treebank: , \t |\t wordpunct_tokenize: ,\n",
      "Treebank: and \t |\t wordpunct_tokenize: sentence\n",
      "Treebank: subword \t |\t wordpunct_tokenize: tokenization\n",
      "Treebank: tokenization. \t |\t wordpunct_tokenize: ,\n",
      "Treebank: Each \t |\t wordpunct_tokenize: and\n",
      "Treebank: method \t |\t wordpunct_tokenize: subword\n",
      "Treebank: has \t |\t wordpunct_tokenize: tokenization\n",
      "Treebank: its \t |\t wordpunct_tokenize: .\n",
      "Treebank: own \t |\t wordpunct_tokenize: Each\n",
      "Treebank: advantages \t |\t wordpunct_tokenize: method\n",
      "Treebank: and \t |\t wordpunct_tokenize: has\n",
      "Treebank: disadvantages \t |\t wordpunct_tokenize: its\n",
      "Treebank: , \t |\t wordpunct_tokenize: own\n",
      "Treebank: and \t |\t wordpunct_tokenize: advantages\n",
      "Treebank: the \t |\t wordpunct_tokenize: and\n",
      "Treebank: choice \t |\t wordpunct_tokenize: disadvantages\n",
      "Treebank: of \t |\t wordpunct_tokenize: ,\n",
      "Treebank: method \t |\t wordpunct_tokenize: and\n",
      "Treebank: depends \t |\t wordpunct_tokenize: the\n",
      "Treebank: on \t |\t wordpunct_tokenize: choice\n",
      "Treebank: the \t |\t wordpunct_tokenize: of\n",
      "Treebank: specific \t |\t wordpunct_tokenize: method\n",
      "Treebank: NLP \t |\t wordpunct_tokenize: depends\n",
      "Treebank: task \t |\t wordpunct_tokenize: on\n",
      "Treebank: at \t |\t wordpunct_tokenize: the\n",
      "Treebank: hand. \t |\t wordpunct_tokenize: specific\n",
      "Treebank: Tokenization \t |\t wordpunct_tokenize: NLP\n",
      "Treebank: is \t |\t wordpunct_tokenize: task\n",
      "Treebank: a \t |\t wordpunct_tokenize: at\n",
      "Treebank: crucial \t |\t wordpunct_tokenize: hand\n",
      "Treebank: step \t |\t wordpunct_tokenize: .\n",
      "Treebank: in \t |\t wordpunct_tokenize: Tokenization\n",
      "Treebank: many \t |\t wordpunct_tokenize: is\n",
      "Treebank: NLP \t |\t wordpunct_tokenize: a\n",
      "Treebank: applications \t |\t wordpunct_tokenize: crucial\n",
      "Treebank: , \t |\t wordpunct_tokenize: step\n",
      "Treebank: such \t |\t wordpunct_tokenize: in\n",
      "Treebank: as \t |\t wordpunct_tokenize: many\n",
      "Treebank: text \t |\t wordpunct_tokenize: NLP\n",
      "Treebank: classification \t |\t wordpunct_tokenize: applications\n",
      "Treebank: , \t |\t wordpunct_tokenize: ,\n",
      "Treebank: sentiment \t |\t wordpunct_tokenize: such\n",
      "Treebank: analysis \t |\t wordpunct_tokenize: as\n",
      "Treebank: , \t |\t wordpunct_tokenize: text\n",
      "Treebank: and \t |\t wordpunct_tokenize: classification\n",
      "Treebank: machine \t |\t wordpunct_tokenize: ,\n",
      "Treebank: translation. \t |\t wordpunct_tokenize: sentiment\n",
      "Treebank: It \t |\t wordpunct_tokenize: analysis\n",
      "Treebank: is \t |\t wordpunct_tokenize: ,\n",
      "Treebank: base \t |\t wordpunct_tokenize: and\n",
      "Treebank: of \t |\t wordpunct_tokenize: machine\n",
      "Treebank: any \t |\t wordpunct_tokenize: translation\n",
      "Treebank: NLP \t |\t wordpunct_tokenize: .\n",
      "Treebank: task \t |\t wordpunct_tokenize: It\n",
      "Treebank: ! \t |\t wordpunct_tokenize: is\n"
     ]
    }
   ],
   "source": [
    "# Compare tree bank tokenizer with wordpunct_tokenize\n",
    "for tbt, wpt in zip(treebank_toks, words_punct):\n",
    "    print(f\"Treebank: {tbt} \\t |\\t wordpunct_tokenize: {wpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563dd235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
