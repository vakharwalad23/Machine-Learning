{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Problem Statement\n",
    "    - \"Trips & Travel.Com\" company wants to enable and establish a viable business model to expand the customer base. One of the ways to expand the customer base is to introduce a new offering of packages. Currently, there are 5 types of packages the company is offering * Basic, Standard, Deluxe, Super Deluxe, King. Looking at the data of the last year, we observed that 18% of the customers purchased the packages. However, the marketing cost was quite high because customers were contacted at random without looking at the available information. The company is now planning to launch a new product i.e. Wellness Tourism Package. Wellness Tourism is defined as Travel that allows the traveler to maintain, enhance or kick-start a healthy lifestyle, and support or increase one's sense of well-being. However, this time company wants to harness the available data of existing and potential customers to make the marketing expenditure more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Dataset\n",
    "    - The Dataset is collected from https://www.kaggle.com/datasets/susant4learning/holiday-package-purchase-prediction The data consists of 20 column and 4888 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Holiday Package Prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Single</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0        Single            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0        Single            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                    0\n",
       "ProdTaken                     0\n",
       "Age                         226\n",
       "TypeofContact                25\n",
       "CityTier                      0\n",
       "DurationOfPitch             251\n",
       "Occupation                    0\n",
       "Gender                        0\n",
       "NumberOfPersonVisiting        0\n",
       "NumberOfFollowups            45\n",
       "ProductPitched                0\n",
       "PreferredPropertyStar        26\n",
       "MaritalStatus                 0\n",
       "NumberOfTrips               140\n",
       "Passport                      0\n",
       "PitchSatisfactionScore        0\n",
       "OwnCar                        0\n",
       "NumberOfChildrenVisiting     66\n",
       "Designation                   0\n",
       "MonthlyIncome               233\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeofContact\n",
      "Self Enquiry       3444\n",
      "Company Invited    1419\n",
      "Name: count, dtype: int64\n",
      "----------------------\n",
      "Occupation\n",
      "Salaried          2368\n",
      "Small Business    2084\n",
      "Large Business     434\n",
      "Free Lancer          2\n",
      "Name: count, dtype: int64\n",
      "----------------------\n",
      "Gender\n",
      "Male       2916\n",
      "Female     1817\n",
      "Fe Male     155\n",
      "Name: count, dtype: int64\n",
      "----------------------\n",
      "ProductPitched\n",
      "Basic           1842\n",
      "Deluxe          1732\n",
      "Standard         742\n",
      "Super Deluxe     342\n",
      "King             230\n",
      "Name: count, dtype: int64\n",
      "----------------------\n",
      "MaritalStatus\n",
      "Married      2340\n",
      "Divorced      950\n",
      "Single        916\n",
      "Unmarried     682\n",
      "Name: count, dtype: int64\n",
      "----------------------\n",
      "Designation\n",
      "Executive         1842\n",
      "Manager           1732\n",
      "Senior Manager     742\n",
      "AVP                342\n",
      "VP                 230\n",
      "Name: count, dtype: int64\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "## Checking for all the unique values in categorical columns\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(df[i].value_counts())\n",
    "        print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'] = df['Gender'].replace('Fe Male', 'Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      2916\n",
       "Female    1972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MaritalStatus'] = df['MaritalStatus'].replace('Single', 'Unmarried')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaritalStatus\n",
       "Married      2340\n",
       "Unmarried    1598\n",
       "Divorced      950\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Treatment\n",
    "feature_columns_with_missing_values = [features for features in df.columns if df[features].isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age: 4.6236 % missing values\n",
      "TypeofContact: 0.5115 % missing values\n",
      "DurationOfPitch: 5.135 % missing values\n",
      "NumberOfFollowups: 0.9206 % missing values\n",
      "PreferredPropertyStar: 0.5319 % missing values\n",
      "NumberOfTrips: 2.8642 % missing values\n",
      "NumberOfChildrenVisiting: 1.3502 % missing values\n",
      "MonthlyIncome: 4.7668 % missing values\n"
     ]
    }
   ],
   "source": [
    "for features in feature_columns_with_missing_values:\n",
    "    print(f\"{features}:\", np.round(df[features].isnull().mean()*100, 4), \"% missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4662.000000</td>\n",
       "      <td>4637.000000</td>\n",
       "      <td>4843.000000</td>\n",
       "      <td>4862.000000</td>\n",
       "      <td>4748.000000</td>\n",
       "      <td>4822.000000</td>\n",
       "      <td>4655.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.622265</td>\n",
       "      <td>15.490835</td>\n",
       "      <td>3.708445</td>\n",
       "      <td>3.581037</td>\n",
       "      <td>3.236521</td>\n",
       "      <td>1.187267</td>\n",
       "      <td>23619.853491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.316387</td>\n",
       "      <td>8.519643</td>\n",
       "      <td>1.002509</td>\n",
       "      <td>0.798009</td>\n",
       "      <td>1.849019</td>\n",
       "      <td>0.857861</td>\n",
       "      <td>5380.698361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20346.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>98678.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age  DurationOfPitch  NumberOfFollowups  PreferredPropertyStar  \\\n",
       "count  4662.000000      4637.000000        4843.000000            4862.000000   \n",
       "mean     37.622265        15.490835           3.708445               3.581037   \n",
       "std       9.316387         8.519643           1.002509               0.798009   \n",
       "min      18.000000         5.000000           1.000000               3.000000   \n",
       "25%      31.000000         9.000000           3.000000               3.000000   \n",
       "50%      36.000000        13.000000           4.000000               3.000000   \n",
       "75%      44.000000        20.000000           4.000000               4.000000   \n",
       "max      61.000000       127.000000           6.000000               5.000000   \n",
       "\n",
       "       NumberOfTrips  NumberOfChildrenVisiting  MonthlyIncome  \n",
       "count    4748.000000               4822.000000    4655.000000  \n",
       "mean        3.236521                  1.187267   23619.853491  \n",
       "std         1.849019                  0.857861    5380.698361  \n",
       "min         1.000000                  0.000000    1000.000000  \n",
       "25%         2.000000                  1.000000   20346.000000  \n",
       "50%         3.000000                  1.000000   22347.000000  \n",
       "75%         4.000000                  2.000000   25571.000000  \n",
       "max        22.000000                  3.000000   98678.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stats of Null numerical columns\n",
    "df[feature_columns_with_missing_values].select_dtypes(exclude=\"object\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0   NaN     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing Missing Values\n",
    "1. Impute Median for Age\n",
    "2. Impute Mode for TypeofContact\n",
    "3. Impute Median for DurationOfPitch\n",
    "4. Impute Mode for NumberOfFollowups as it is Discrete Feature\n",
    "5. Impute Mode for PreferredPropertyStar\n",
    "6. Impute Median for NumberOfTrips\n",
    "7. Impute Mode for NumberOfChildrenVisiting\n",
    "8. Impute Median for MonthlyIncome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation\n",
    "df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "df['DurationOfPitch'] = df['DurationOfPitch'].fillna(df['DurationOfPitch'].median())\n",
    "df['NumberOfTrips'] = df['NumberOfTrips'].fillna(df['NumberOfTrips'].median())\n",
    "df['MonthlyIncome'] = df['MonthlyIncome'].fillna(df['MonthlyIncome'].median())\n",
    "\n",
    "# Mode imputation\n",
    "df['TypeofContact'] = df['TypeofContact'].fillna(df['TypeofContact'].mode()[0])\n",
    "df['NumberOfFollowups'] = df['NumberOfFollowups'].fillna(df['NumberOfFollowups'].mode()[0])\n",
    "df['PreferredPropertyStar'] = df['PreferredPropertyStar'].fillna(df['PreferredPropertyStar'].mode()[0])\n",
    "df['NumberOfChildrenVisiting'] = df['NumberOfChildrenVisiting'].fillna(df['NumberOfChildrenVisiting'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200004</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0      200000          1  41.0     Self Enquiry         3              6.0   \n",
       "1      200001          0  49.0  Company Invited         1             14.0   \n",
       "2      200002          1  37.0     Self Enquiry         1              8.0   \n",
       "3      200003          0  33.0  Company Invited         1              9.0   \n",
       "4      200004          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerID                  0\n",
       "ProdTaken                   0\n",
       "Age                         0\n",
       "TypeofContact               0\n",
       "CityTier                    0\n",
       "DurationOfPitch             0\n",
       "Occupation                  0\n",
       "Gender                      0\n",
       "NumberOfPersonVisiting      0\n",
       "NumberOfFollowups           0\n",
       "ProductPitched              0\n",
       "PreferredPropertyStar       0\n",
       "MaritalStatus               0\n",
       "NumberOfTrips               0\n",
       "Passport                    0\n",
       "PitchSatisfactionScore      0\n",
       "OwnCar                      0\n",
       "NumberOfChildrenVisiting    0\n",
       "Designation                 0\n",
       "MonthlyIncome               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CustomerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfPersonVisiting</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>NumberOfChildrenVisiting</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0          1  41.0     Self Enquiry         3              6.0   \n",
       "1          0  49.0  Company Invited         1             14.0   \n",
       "2          1  37.0     Self Enquiry         1              8.0   \n",
       "3          0  33.0  Company Invited         1              9.0   \n",
       "4          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfPersonVisiting  NumberOfFollowups  \\\n",
       "0        Salaried  Female                       3                3.0   \n",
       "1        Salaried    Male                       3                4.0   \n",
       "2     Free Lancer    Male                       3                4.0   \n",
       "3        Salaried  Female                       2                3.0   \n",
       "4  Small Business    Male                       2                3.0   \n",
       "\n",
       "  ProductPitched  PreferredPropertyStar MaritalStatus  NumberOfTrips  \\\n",
       "0         Deluxe                    3.0     Unmarried            1.0   \n",
       "1         Deluxe                    4.0      Divorced            2.0   \n",
       "2          Basic                    3.0     Unmarried            7.0   \n",
       "3          Basic                    3.0      Divorced            2.0   \n",
       "4          Basic                    4.0      Divorced            1.0   \n",
       "\n",
       "   Passport  PitchSatisfactionScore  OwnCar  NumberOfChildrenVisiting  \\\n",
       "0         1                       2       1                       0.0   \n",
       "1         0                       3       1                       2.0   \n",
       "2         1                       3       0                       0.0   \n",
       "3         1                       5       1                       1.0   \n",
       "4         0                       5       1                       0.0   \n",
       "\n",
       "  Designation  MonthlyIncome  \n",
       "0     Manager        20993.0  \n",
       "1     Manager        20130.0  \n",
       "2   Executive        17090.0  \n",
       "3   Executive        17909.0  \n",
       "4   Executive        18468.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalVisiting'] = df['NumberOfPersonVisiting'] + df['NumberOfChildrenVisiting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['NumberOfPersonVisiting', 'NumberOfChildrenVisiting'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdTaken</th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>TotalVisiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProdTaken   Age    TypeofContact  CityTier  DurationOfPitch  \\\n",
       "0          1  41.0     Self Enquiry         3              6.0   \n",
       "1          0  49.0  Company Invited         1             14.0   \n",
       "2          1  37.0     Self Enquiry         1              8.0   \n",
       "3          0  33.0  Company Invited         1              9.0   \n",
       "4          0  36.0     Self Enquiry         1              8.0   \n",
       "\n",
       "       Occupation  Gender  NumberOfFollowups ProductPitched  \\\n",
       "0        Salaried  Female                3.0         Deluxe   \n",
       "1        Salaried    Male                4.0         Deluxe   \n",
       "2     Free Lancer    Male                4.0          Basic   \n",
       "3        Salaried  Female                3.0          Basic   \n",
       "4  Small Business    Male                3.0          Basic   \n",
       "\n",
       "   PreferredPropertyStar MaritalStatus  NumberOfTrips  Passport  \\\n",
       "0                    3.0     Unmarried            1.0         1   \n",
       "1                    4.0      Divorced            2.0         0   \n",
       "2                    3.0     Unmarried            7.0         1   \n",
       "3                    3.0      Divorced            2.0         1   \n",
       "4                    4.0      Divorced            1.0         0   \n",
       "\n",
       "   PitchSatisfactionScore  OwnCar Designation  MonthlyIncome  TotalVisiting  \n",
       "0                       2       1     Manager        20993.0            3.0  \n",
       "1                       3       1     Manager        20130.0            5.0  \n",
       "2                       3       0   Executive        17090.0            3.0  \n",
       "3                       5       1   Executive        17909.0            3.0  \n",
       "4                       5       1   Executive        18468.0            2.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_num_features = df.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['ProdTaken', 'Age', 'CityTier', 'DurationOfPitch', 'NumberOfFollowups',\n",
       "        'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
       "        'PitchSatisfactionScore', 'OwnCar', 'MonthlyIncome', 'TotalVisiting'],\n",
       "       dtype='object'),\n",
       " 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_num_features, len(no_num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Features\n",
    "no_cat_features = df.select_dtypes(include=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['TypeofContact', 'Occupation', 'Gender', 'ProductPitched',\n",
       "        'MaritalStatus', 'Designation'],\n",
       "       dtype='object'),\n",
       " 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Categorical Features\n",
    "no_cat_features, len(no_cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete Variables Count: 9\n"
     ]
    }
   ],
   "source": [
    "## Discrete Features\n",
    "discrete_features = [feature for feature in no_num_features if len(df[feature].unique()) < 25]\n",
    "print(f\"Discrete Variables Count: {len(discrete_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous feature Count 3\n"
     ]
    }
   ],
   "source": [
    "## Continuous Features\n",
    "continuous_features = [feature for feature in no_num_features if feature not in discrete_features]\n",
    "print(f\"Continuous feature Count {len(continuous_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['ProdTaken'], axis=1)\n",
    "y = df['ProdTaken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdTaken\n",
       "0    3968\n",
       "1     920\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>TypeofContact</th>\n",
       "      <th>CityTier</th>\n",
       "      <th>DurationOfPitch</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Gender</th>\n",
       "      <th>NumberOfFollowups</th>\n",
       "      <th>ProductPitched</th>\n",
       "      <th>PreferredPropertyStar</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>NumberOfTrips</th>\n",
       "      <th>Passport</th>\n",
       "      <th>PitchSatisfactionScore</th>\n",
       "      <th>OwnCar</th>\n",
       "      <th>Designation</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>TotalVisiting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20993.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Deluxe</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Manager</td>\n",
       "      <td>20130.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Free Lancer</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17090.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Company Invited</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>17909.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>Self Enquiry</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Small Business</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Executive</td>\n",
       "      <td>18468.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age    TypeofContact  CityTier  DurationOfPitch      Occupation  Gender  \\\n",
       "0  41.0     Self Enquiry         3              6.0        Salaried  Female   \n",
       "1  49.0  Company Invited         1             14.0        Salaried    Male   \n",
       "2  37.0     Self Enquiry         1              8.0     Free Lancer    Male   \n",
       "3  33.0  Company Invited         1              9.0        Salaried  Female   \n",
       "4  36.0     Self Enquiry         1              8.0  Small Business    Male   \n",
       "\n",
       "   NumberOfFollowups ProductPitched  PreferredPropertyStar MaritalStatus  \\\n",
       "0                3.0         Deluxe                    3.0     Unmarried   \n",
       "1                4.0         Deluxe                    4.0      Divorced   \n",
       "2                4.0          Basic                    3.0     Unmarried   \n",
       "3                3.0          Basic                    3.0      Divorced   \n",
       "4                3.0          Basic                    4.0      Divorced   \n",
       "\n",
       "   NumberOfTrips  Passport  PitchSatisfactionScore  OwnCar Designation  \\\n",
       "0            1.0         1                       2       1     Manager   \n",
       "1            2.0         0                       3       1     Manager   \n",
       "2            7.0         1                       3       0   Executive   \n",
       "3            2.0         1                       5       1   Executive   \n",
       "4            1.0         0                       5       1   Executive   \n",
       "\n",
       "   MonthlyIncome  TotalVisiting  \n",
       "0        20993.0            3.0  \n",
       "1        20130.0            5.0  \n",
       "2        17090.0            3.0  \n",
       "3        17909.0            3.0  \n",
       "4        18468.0            2.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3421, 17), (1467, 17))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TypeofContact', 'Occupation', 'Gender', 'ProductPitched',\n",
       "       'MaritalStatus', 'Designation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer ## Column Transformer is used to apply different preprocessing to different columns\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "ohe_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", ohe_transformer, cat_features),\n",
    "        (\"StandardScaler\", numeric_transformer, num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for ColumnTransformer</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>ColumnTransformer(transformers=[(&#x27;OneHotEncoder&#x27;, OneHotEncoder(drop=&#x27;first&#x27;),\n",
       "                                 Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)),\n",
       "                                (&#x27;StandardScaler&#x27;, StandardScaler(),\n",
       "                                 Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;))])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div></label><div class=\"sk-toggleable__content \"><pre>Index([&#x27;TypeofContact&#x27;, &#x27;Occupation&#x27;, &#x27;Gender&#x27;, &#x27;ProductPitched&#x27;,\n",
       "       &#x27;MaritalStatus&#x27;, &#x27;Designation&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></div></label><div class=\"sk-toggleable__content \"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div></label><div class=\"sk-toggleable__content \"><pre>Index([&#x27;Age&#x27;, &#x27;CityTier&#x27;, &#x27;DurationOfPitch&#x27;, &#x27;NumberOfFollowups&#x27;,\n",
       "       &#x27;PreferredPropertyStar&#x27;, &#x27;NumberOfTrips&#x27;, &#x27;Passport&#x27;,\n",
       "       &#x27;PitchSatisfactionScore&#x27;, &#x27;OwnCar&#x27;, &#x27;MonthlyIncome&#x27;, &#x27;TotalVisiting&#x27;],\n",
       "      dtype=&#x27;object&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></div></label><div class=\"sk-toggleable__content \"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('OneHotEncoder', OneHotEncoder(drop='first'),\n",
       "                                 Index(['TypeofContact', 'Occupation', 'Gender', 'ProductPitched',\n",
       "       'MaritalStatus', 'Designation'],\n",
       "      dtype='object')),\n",
       "                                ('StandardScaler', StandardScaler(),\n",
       "                                 Index(['Age', 'CityTier', 'DurationOfPitch', 'NumberOfFollowups',\n",
       "       'PreferredPropertyStar', 'NumberOfTrips', 'Passport',\n",
       "       'PitchSatisfactionScore', 'OwnCar', 'MonthlyIncome', 'TotalVisiting'],\n",
       "      dtype='object'))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.649789</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>1.409081</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>0.460318</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.527737</td>\n",
       "      <td>-0.719632</td>\n",
       "      <td>1.768057</td>\n",
       "      <td>1.504605</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>1.409081</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>-1.005668</td>\n",
       "      <td>-0.777901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.161582</td>\n",
       "      <td>1.281068</td>\n",
       "      <td>1.768057</td>\n",
       "      <td>-0.672975</td>\n",
       "      <td>1.580492</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-1.209722</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>-0.771841</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.520424</td>\n",
       "      <td>-0.128580</td>\n",
       "      <td>1.580492</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.527737</td>\n",
       "      <td>1.281068</td>\n",
       "      <td>0.520424</td>\n",
       "      <td>2.593396</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>0.681134</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>-0.423411</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3416</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.649789</td>\n",
       "      <td>1.281068</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-0.672975</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-1.502707</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.531926</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>-0.893893</td>\n",
       "      <td>-0.719632</td>\n",
       "      <td>1.768057</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>1.409081</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>1.512744</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>1.547143</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>2.049001</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.774760</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.357400</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>1.791246</td>\n",
       "      <td>1.281068</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-0.128580</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-1.502707</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.250765</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.771841</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>1.580492</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>-1.071680</td>\n",
       "      <td>-1.487933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3421 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...        16  \\\n",
       "0     1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  ... -0.714031   \n",
       "1     1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ... -0.714031   \n",
       "2     1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.714031   \n",
       "3     1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  1.470853   \n",
       "4     1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.714031   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "3416  1.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.714031   \n",
       "3417  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  1.470853   \n",
       "3418  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.470853   \n",
       "3419  1.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ...  1.470853   \n",
       "3420  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ... -0.714031   \n",
       "\n",
       "            17        18        19        20        21        22        23  \\\n",
       "0    -0.649789  0.280718 -0.727208 -1.217370 -0.632714  1.409081  0.781435   \n",
       "1    -0.527737 -0.719632  1.768057  1.504605 -0.632714  1.409081 -1.279697   \n",
       "2    -0.161582  1.281068  1.768057 -0.672975  1.580492 -0.046813  0.781435   \n",
       "3    -0.771841  0.280718  0.520424 -0.128580  1.580492 -0.046813  0.781435   \n",
       "4    -0.527737  1.281068  0.520424  2.593396 -0.632714  0.681134 -1.279697   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3416 -0.649789  1.281068 -0.727208 -0.672975 -0.632714 -1.502707  0.781435   \n",
       "3417 -0.893893 -0.719632  1.768057 -1.217370 -0.632714  1.409081  0.781435   \n",
       "3418  1.547143  0.280718 -0.727208  2.049001 -0.632714 -0.774760  0.781435   \n",
       "3419  1.791246  1.281068 -0.727208 -0.128580 -0.632714 -1.502707  0.781435   \n",
       "3420 -0.771841  0.280718 -0.727208 -1.217370  1.580492 -0.046813 -1.279697   \n",
       "\n",
       "            24        25  \n",
       "0     0.460318 -0.067869  \n",
       "1    -1.005668 -0.777901  \n",
       "2    -1.209722 -0.067869  \n",
       "3    -0.017750  0.642163  \n",
       "4    -0.423411 -0.067869  \n",
       "...        ...       ...  \n",
       "3416 -0.531926  0.642163  \n",
       "3417  1.512744 -0.067869  \n",
       "3418 -0.357400  0.642163  \n",
       "3419 -0.250765  0.642163  \n",
       "3420 -1.071680 -1.487933  \n",
       "\n",
       "[3421 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>-0.283634</td>\n",
       "      <td>1.281068</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.774760</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>-0.730338</td>\n",
       "      <td>-0.777901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378411</td>\n",
       "      <td>-0.527737</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.520424</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>1.580492</td>\n",
       "      <td>1.409081</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>-0.663950</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>0.814832</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>0.960210</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>1.409081</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.417017</td>\n",
       "      <td>-0.777901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>2.523557</td>\n",
       "      <td>2.281418</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>1.504605</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.113100</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.470853</td>\n",
       "      <td>-1.015945</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.520424</td>\n",
       "      <td>-0.128580</td>\n",
       "      <td>1.580492</td>\n",
       "      <td>0.681134</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.314332</td>\n",
       "      <td>2.062226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>1.791246</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>-0.128580</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>1.022828</td>\n",
       "      <td>0.642163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-0.771841</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>0.415815</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-1.502707</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.540201</td>\n",
       "      <td>1.352195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>1.303039</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>0.520424</td>\n",
       "      <td>1.504605</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>-0.080752</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-1.015945</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>-0.727208</td>\n",
       "      <td>1.504605</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>-0.046813</td>\n",
       "      <td>0.781435</td>\n",
       "      <td>1.975766</td>\n",
       "      <td>-0.067869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.714031</td>\n",
       "      <td>-1.137996</td>\n",
       "      <td>0.280718</td>\n",
       "      <td>1.768057</td>\n",
       "      <td>-1.217370</td>\n",
       "      <td>-0.632714</td>\n",
       "      <td>0.681134</td>\n",
       "      <td>-1.279697</td>\n",
       "      <td>1.288380</td>\n",
       "      <td>-1.487933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1467 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4    5    6    7    8    9   ...        16  \\\n",
       "0     0.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  1.0  ...  1.470853   \n",
       "1     1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  1.0  ...  0.378411   \n",
       "2     1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  1.0  ...  1.470853   \n",
       "3     1.0  0.0  0.0  1.0  1.0  1.0  0.0  0.0  0.0  0.0  ... -0.714031   \n",
       "4     1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.470853   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "1462  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  ... -0.714031   \n",
       "1463  1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ... -0.714031   \n",
       "1464  0.0  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  ... -0.714031   \n",
       "1465  1.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  ... -0.714031   \n",
       "1466  1.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  ... -0.714031   \n",
       "\n",
       "            17        18        19        20        21        22        23  \\\n",
       "0    -0.283634  1.281068 -0.727208 -1.217370 -0.632714 -0.774760 -1.279697   \n",
       "1    -0.527737  0.280718  0.520424 -1.217370  1.580492  1.409081 -1.279697   \n",
       "2     0.814832  0.280718 -0.727208  0.960210 -0.632714  1.409081  0.781435   \n",
       "3     2.523557  2.281418 -0.727208  1.504605 -0.632714 -0.046813  0.781435   \n",
       "4    -1.015945  0.280718  0.520424 -0.128580  1.580492  0.681134  0.781435   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1462  1.791246  0.280718 -0.727208 -0.128580 -0.632714 -0.046813  0.781435   \n",
       "1463 -0.771841  0.280718 -0.727208  0.415815 -0.632714 -1.502707  0.781435   \n",
       "1464  1.303039  0.280718  0.520424  1.504605 -0.632714 -0.046813  0.781435   \n",
       "1465 -1.015945  0.280718 -0.727208  1.504605 -0.632714 -0.046813  0.781435   \n",
       "1466 -1.137996  0.280718  1.768057 -1.217370 -0.632714  0.681134 -1.279697   \n",
       "\n",
       "            24        25  \n",
       "0    -0.730338 -0.777901  \n",
       "1    -0.663950 -0.067869  \n",
       "2    -0.417017 -0.777901  \n",
       "3    -0.113100  0.642163  \n",
       "4    -0.314332  2.062226  \n",
       "...        ...       ...  \n",
       "1462  1.022828  0.642163  \n",
       "1463 -0.540201  1.352195  \n",
       "1464 -0.080752 -0.067869  \n",
       "1465  1.975766 -0.067869  \n",
       "1466  1.288380 -1.487933  \n",
       "\n",
       "[1467 rows x 26 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logisitic Regression\":LogisticRegression(),\n",
    "    \"Decision Tree\":DecisionTreeClassifier(),\n",
    "    \"Random Forest\":RandomForestClassifier(),\n",
    "    \"Gradient Boost\":GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logisitic Regression\n",
      "Training Metrics:\n",
      "Training Accuracy: 0.8450745396083017\n",
      "Training F1 Score: 0.8188300489955811\n",
      "Training Precision: 0.7101449275362319\n",
      "Training Recall: 0.30340557275541796\n",
      "Training ROC AUC: 0.6372883719632946\n",
      "Training Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      2775\n",
      "           1       0.71      0.30      0.43       646\n",
      "\n",
      "    accuracy                           0.85      3421\n",
      "   macro avg       0.78      0.64      0.67      3421\n",
      "weighted avg       0.83      0.85      0.82      3421\n",
      "\n",
      "Training Confusion Matrix: \n",
      "[[2695   80]\n",
      " [ 450  196]]\n",
      "-----------------------------------\n",
      "\n",
      "Testing Metrics:\n",
      "Testing Accuracy: 0.8432174505794138\n",
      "Testing F1 Score: 0.8192671796105939\n",
      "Testing Precision: 0.671875\n",
      "Testing Recall: 0.31386861313868614\n",
      "Testing ROC AUC: 0.6393316242558477\n",
      "Testing Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      1193\n",
      "           1       0.67      0.31      0.43       274\n",
      "\n",
      "    accuracy                           0.84      1467\n",
      "   macro avg       0.77      0.64      0.67      1467\n",
      "weighted avg       0.82      0.84      0.82      1467\n",
      "\n",
      "Testing Confusion Matrix: \n",
      "[[1151   42]\n",
      " [ 188   86]]\n",
      "===================================\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "Training Metrics:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Precision: 1.0\n",
      "Training Recall: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Training Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2775\n",
      "           1       1.00      1.00      1.00       646\n",
      "\n",
      "    accuracy                           1.00      3421\n",
      "   macro avg       1.00      1.00      1.00      3421\n",
      "weighted avg       1.00      1.00      1.00      3421\n",
      "\n",
      "Training Confusion Matrix: \n",
      "[[2775    0]\n",
      " [   0  646]]\n",
      "-----------------------------------\n",
      "\n",
      "Testing Metrics:\n",
      "Testing Accuracy: 0.8991138377641446\n",
      "Testing F1 Score: 0.899669938312921\n",
      "Testing Precision: 0.723404255319149\n",
      "Testing Recall: 0.7445255474452555\n",
      "Testing ROC AUC: 0.8395720779975648\n",
      "Testing Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.94      1193\n",
      "           1       0.72      0.74      0.73       274\n",
      "\n",
      "    accuracy                           0.90      1467\n",
      "   macro avg       0.83      0.84      0.84      1467\n",
      "weighted avg       0.90      0.90      0.90      1467\n",
      "\n",
      "Testing Confusion Matrix: \n",
      "[[1115   78]\n",
      " [  70  204]]\n",
      "===================================\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "Training Metrics:\n",
      "Training Accuracy: 1.0\n",
      "Training F1 Score: 1.0\n",
      "Training Precision: 1.0\n",
      "Training Recall: 1.0\n",
      "Training ROC AUC: 1.0\n",
      "Training Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2775\n",
      "           1       1.00      1.00      1.00       646\n",
      "\n",
      "    accuracy                           1.00      3421\n",
      "   macro avg       1.00      1.00      1.00      3421\n",
      "weighted avg       1.00      1.00      1.00      3421\n",
      "\n",
      "Training Confusion Matrix: \n",
      "[[2775    0]\n",
      " [   0  646]]\n",
      "-----------------------------------\n",
      "\n",
      "Testing Metrics:\n",
      "Testing Accuracy: 0.9229720518064076\n",
      "Testing F1 Score: 0.9170586073597025\n",
      "Testing Precision: 0.93048128342246\n",
      "Testing Recall: 0.635036496350365\n",
      "Testing ROC AUC: 0.812069798887672\n",
      "Testing Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      1193\n",
      "           1       0.93      0.64      0.75       274\n",
      "\n",
      "    accuracy                           0.92      1467\n",
      "   macro avg       0.93      0.81      0.85      1467\n",
      "weighted avg       0.92      0.92      0.92      1467\n",
      "\n",
      "Testing Confusion Matrix: \n",
      "[[1180   13]\n",
      " [ 100  174]]\n",
      "===================================\n",
      "\n",
      "\n",
      "Model: Gradient Boost\n",
      "Training Metrics:\n",
      "Training Accuracy: 0.8947676118094124\n",
      "Training F1 Score: 0.8833080091835576\n",
      "Training Precision: 0.8803191489361702\n",
      "Training Recall: 0.5123839009287926\n",
      "Training ROC AUC: 0.7480838423562882\n",
      "Training Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      2775\n",
      "           1       0.88      0.51      0.65       646\n",
      "\n",
      "    accuracy                           0.89      3421\n",
      "   macro avg       0.89      0.75      0.79      3421\n",
      "weighted avg       0.89      0.89      0.88      3421\n",
      "\n",
      "Training Confusion Matrix: \n",
      "[[2730   45]\n",
      " [ 315  331]]\n",
      "-----------------------------------\n",
      "\n",
      "Testing Metrics:\n",
      "Testing Accuracy: 0.8766189502385822\n",
      "Testing F1 Score: 0.862755990612703\n",
      "Testing Precision: 0.7961783439490446\n",
      "Testing Recall: 0.4562043795620438\n",
      "Testing ROC AUC: 0.714690622304073\n",
      "Testing Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      1193\n",
      "           1       0.80      0.46      0.58       274\n",
      "\n",
      "    accuracy                           0.88      1467\n",
      "   macro avg       0.84      0.71      0.75      1467\n",
      "weighted avg       0.87      0.88      0.86      1467\n",
      "\n",
      "Testing Confusion Matrix: \n",
      "[[1161   32]\n",
      " [ 149  125]]\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(list(models))):\n",
    "    model = list(models.values())[m]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    ## Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    ## Training Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    train_classification_report = classification_report(y_train, y_train_pred)\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "    ## Testing Accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    test_classification_report = classification_report(y_test, y_pred)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {list(models.keys())[m]}\")\n",
    "\n",
    "    print(\"Training Metrics:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Training F1 Score: {train_f1}\")\n",
    "    print(f\"Training Precision: {train_precision}\")\n",
    "    print(f\"Training Recall: {train_recall}\")\n",
    "    print(f\"Training ROC AUC: {train_roc_auc}\")\n",
    "    print(f\"Training Classification Report: \\n{train_classification_report}\")\n",
    "    print(f\"Training Confusion Matrix: \\n{train_confusion_matrix}\")\n",
    "\n",
    "    print('-'*35)\n",
    "\n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "    print(f\"Testing F1 Score: {test_f1}\")\n",
    "    print(f\"Testing Precision: {test_precision}\")\n",
    "    print(f\"Testing Recall: {test_recall}\")\n",
    "    print(f\"Testing ROC AUC: {test_roc_auc}\")\n",
    "    print(f\"Testing Classification Report: \\n{test_classification_report}\")\n",
    "    print(f\"Testing Confusion Matrix: \\n{test_confusion_matrix}\")\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_params = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomcv_models = [\n",
    "    ('Gradient Boost', GradientBoostingClassifier(), gb_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.75; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=log_loss, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.75; total time=   0.9s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=5, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=300, subsample=0.75; total time=   0.8s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=2, n_estimators=200, subsample=1.0; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=300, subsample=1.0; total time=   1.0s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=200, subsample=0.75; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=5, n_estimators=50, subsample=0.75; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=squared_error, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=1.0; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.6s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=10, n_estimators=300, subsample=0.5; total time=   0.7s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=exponential, min_samples_split=2, n_estimators=50, subsample=0.5; total time=   0.1s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=log_loss, min_samples_split=10, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=100, subsample=0.5; total time=   0.2s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.1, loss=exponential, min_samples_split=5, n_estimators=200, subsample=0.5; total time=   0.4s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.3s\n",
      "[CV] END criterion=friedman_mse, learning_rate=0.5, loss=log_loss, min_samples_split=10, n_estimators=100, subsample=1.0; total time=   0.4s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.01, loss=exponential, min_samples_split=10, n_estimators=200, subsample=0.75; total time=   0.5s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.8s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.9s\n",
      "[CV] END criterion=squared_error, learning_rate=0.1, loss=exponential, min_samples_split=10, n_estimators=300, subsample=1.0; total time=   0.8s\n"
     ]
    }
   ],
   "source": [
    "for name, model, params in randomcv_models:\n",
    "    rs_cv = RandomizedSearchCV(estimator=model, param_distributions=params, n_iter=100, cv=5, verbose=2, n_jobs=-1)\n",
    "    rs_cv.fit(X_train, y_train)\n",
    "    model_params[name] = rs_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Best Parameters for Gradient Boost----------------------\n",
      "{'subsample': 1.0, 'n_estimators': 300, 'min_samples_split': 10, 'loss': 'log_loss', 'learning_rate': 0.5, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_params:\n",
    "    print(f\"----------------------Best Parameters for {model_name}----------------------\")\n",
    "    print(model_params[model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Gradient Boost': GradientBoostingClassifier(subsample= 1.0, n_estimators= 300, min_samples_split= 10, loss= 'log_loss', learning_rate= 0.5, criterion= 'friedman_mse')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Gradient Boost\n",
      "Training Metrics:\n",
      "Training Accuracy: 0.9994153756211634\n",
      "Training F1 Score: 0.9994150277237506\n",
      "Training Precision: 1.0\n",
      "Training Recall: 0.9969040247678018\n",
      "Training ROC AUC: 0.9984520123839009\n",
      "Training Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2775\n",
      "           1       1.00      1.00      1.00       646\n",
      "\n",
      "    accuracy                           1.00      3421\n",
      "   macro avg       1.00      1.00      1.00      3421\n",
      "weighted avg       1.00      1.00      1.00      3421\n",
      "\n",
      "Training Confusion Matrix: \n",
      "[[2775    0]\n",
      " [   2  644]]\n",
      "-----------------------------------\n",
      "\n",
      "Testing Metrics:\n",
      "Testing Accuracy: 0.9120654396728016\n",
      "Testing F1 Score: 0.9083132504498498\n",
      "Testing Precision: 0.8280542986425339\n",
      "Testing Recall: 0.6678832116788321\n",
      "Testing ROC AUC: 0.8180153694605391\n",
      "Testing Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95      1193\n",
      "           1       0.83      0.67      0.74       274\n",
      "\n",
      "    accuracy                           0.91      1467\n",
      "   macro avg       0.88      0.82      0.84      1467\n",
      "weighted avg       0.91      0.91      0.91      1467\n",
      "\n",
      "Testing Confusion Matrix: \n",
      "[[1155   38]\n",
      " [  91  183]]\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(list(models))):\n",
    "    model = list(models.values())[m]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    ## Predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    ## Training Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "    train_precision = precision_score(y_train, y_train_pred)\n",
    "    train_recall = recall_score(y_train, y_train_pred)\n",
    "    train_roc_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    train_classification_report = classification_report(y_train, y_train_pred)\n",
    "    train_confusion_matrix = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "    ## Testing Accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    test_classification_report = classification_report(y_test, y_pred)\n",
    "    test_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model: {list(models.keys())[m]}\")\n",
    "\n",
    "    print(\"Training Metrics:\")\n",
    "    print(f\"Training Accuracy: {train_accuracy}\")\n",
    "    print(f\"Training F1 Score: {train_f1}\")\n",
    "    print(f\"Training Precision: {train_precision}\")\n",
    "    print(f\"Training Recall: {train_recall}\")\n",
    "    print(f\"Training ROC AUC: {train_roc_auc}\")\n",
    "    print(f\"Training Classification Report: \\n{train_classification_report}\")\n",
    "    print(f\"Training Confusion Matrix: \\n{train_confusion_matrix}\")\n",
    "\n",
    "    print('-'*35)\n",
    "\n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "    print(f\"Testing F1 Score: {test_f1}\")\n",
    "    print(f\"Testing Precision: {test_precision}\")\n",
    "    print(f\"Testing Recall: {test_recall}\")\n",
    "    print(f\"Testing ROC AUC: {test_roc_auc}\")\n",
    "    print(f\"Testing Classification Report: \\n{test_classification_report}\")\n",
    "    print(f\"Testing Confusion Matrix: \\n{test_confusion_matrix}\")\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot ROC AUC Curve\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "plt.figure()\n",
    "\n",
    "# Add the models to the list that you want to view on the ROC plot\n",
    "auc_models = [\n",
    "{\n",
    "    'label': 'Gradient Boost',\n",
    "    'model': GradientBoostingClassifier(subsample= 1.0, n_estimators= 300, min_samples_split= 10, loss= 'log_loss', learning_rate= 0.5, criterion= 'friedman_mse'),\n",
    "    'auc':  0.8180\n",
    "},\n",
    "    \n",
    "]\n",
    "# create loop through all model\n",
    "for algo in auc_models:\n",
    "    model = algo['model']\n",
    "    model.fit(X_train, y_train)\n",
    "# Compute False postive rate, and True positive rate\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "# Calculate Area under the curve to display on the plot\n",
    "    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (algo['label'], algo['auc']))\n",
    "# Custom settings for the plot \n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1-Specificity(False Positive Rate)')\n",
    "plt.ylabel('Sensitivity(True Positive Rate)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"auc.png\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
